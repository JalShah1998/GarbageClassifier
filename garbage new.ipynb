{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout\n",
    "from keras.models  import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "import random,os,glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'Garbage classification/Garbage classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2527"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2276 images belonging to 6 classes.\n",
      "Found 251 images belonging to 6 classes.\n",
      "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n"
     ]
    }
   ],
   "source": [
    "train=ImageDataGenerator(horizontal_flip=True, vertical_flip=True,validation_split=0.1,rescale=1./255,\n",
    "                         shear_range = 0.1,zoom_range = 0.1,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,)\n",
    "test=ImageDataGenerator(rescale=1/255,validation_split=0.1)\n",
    "train_generator=train.flow_from_directory(dir_path,target_size=(300,300),batch_size=32,\n",
    "                                          class_mode='categorical',subset='training')\n",
    "test_generator=test.flow_from_directory(dir_path,target_size=(300,300),batch_size=32,\n",
    "                                        class_mode='categorical',subset='validation')\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "    \n",
    "model.add(Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "model.add(Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "model.add(Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "filepath=\"trained_model.h5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2803776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,842,022\n",
      "Trainable params: 2,842,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "71/71 [==============================] - 131s 2s/step - loss: 1.7401 - acc: 0.2786 - val_loss: 1.6651 - val_acc: 0.2411\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24107, saving model to trained_model.h5\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 129s 2s/step - loss: 1.4888 - acc: 0.3825 - val_loss: 1.7184 - val_acc: 0.3014\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.24107 to 0.30137, saving model to trained_model.h5\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 132s 2s/step - loss: 1.3869 - acc: 0.4313 - val_loss: 1.3627 - val_acc: 0.4840\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30137 to 0.48402, saving model to trained_model.h5\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 134s 2s/step - loss: 1.2677 - acc: 0.4991 - val_loss: 1.2348 - val_acc: 0.4977\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.48402 to 0.49772, saving model to trained_model.h5\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 135s 2s/step - loss: 1.2275 - acc: 0.5167 - val_loss: 1.2815 - val_acc: 0.4749\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49772\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 135s 2s/step - loss: 1.1888 - acc: 0.5423 - val_loss: 1.3105 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.49772 to 0.50685, saving model to trained_model.h5\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 1.1211 - acc: 0.5734 - val_loss: 1.1699 - val_acc: 0.5297\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.50685 to 0.52968, saving model to trained_model.h5\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 1.1068 - acc: 0.5692 - val_loss: 1.2095 - val_acc: 0.5297\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.52968 to 0.52968, saving model to trained_model.h5\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 1.0996 - acc: 0.5828 - val_loss: 1.1483 - val_acc: 0.5179\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.52968\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 1.1687 - acc: 0.5481 - val_loss: 1.1986 - val_acc: 0.5936\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52968 to 0.59361, saving model to trained_model.h5\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 1.0498 - acc: 0.5959 - val_loss: 1.3096 - val_acc: 0.4703\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.59361\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 1.0188 - acc: 0.6038 - val_loss: 1.1176 - val_acc: 0.5297\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.59361\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 1.0398 - acc: 0.6012 - val_loss: 1.1273 - val_acc: 0.5525\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.59361\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 195s 3s/step - loss: 0.9571 - acc: 0.6377 - val_loss: 1.1124 - val_acc: 0.5936\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.59361 to 0.59361, saving model to trained_model.h5\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 144s 2s/step - loss: 0.9558 - acc: 0.6426 - val_loss: 1.1212 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.59361\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.9323 - acc: 0.6518 - val_loss: 1.1436 - val_acc: 0.5342\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.59361\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.9133 - acc: 0.6615 - val_loss: 1.0760 - val_acc: 0.5759\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59361\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.9017 - acc: 0.6607 - val_loss: 1.0967 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59361\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.9678 - acc: 0.6502 - val_loss: 1.0881 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.59361\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.8665 - acc: 0.6730 - val_loss: 1.0378 - val_acc: 0.6073\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.59361 to 0.60731, saving model to trained_model.h5\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.8514 - acc: 0.6923 - val_loss: 1.2463 - val_acc: 0.5525\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.60731\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.9319 - acc: 0.6501 - val_loss: 1.0625 - val_acc: 0.6164\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.60731 to 0.61644, saving model to trained_model.h5\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.8396 - acc: 0.6845 - val_loss: 1.0603 - val_acc: 0.6073\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61644\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.8056 - acc: 0.7033 - val_loss: 1.0239 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61644\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.7885 - acc: 0.7078 - val_loss: 0.9799 - val_acc: 0.6339\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.61644 to 0.63393, saving model to trained_model.h5\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.7425 - acc: 0.7205 - val_loss: 1.0226 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.63393 to 0.65297, saving model to trained_model.h5\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.7710 - acc: 0.7161 - val_loss: 1.0940 - val_acc: 0.6347\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.65297\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.7533 - acc: 0.7276 - val_loss: 0.9766 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.65297\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.7336 - acc: 0.7333 - val_loss: 1.0714 - val_acc: 0.6301\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.65297\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.7335 - acc: 0.7342 - val_loss: 0.9079 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.65297 to 0.68950, saving model to trained_model.h5\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.7249 - acc: 0.7486 - val_loss: 1.1231 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.68950\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 140s 2s/step - loss: 0.6922 - acc: 0.7421 - val_loss: 1.1690 - val_acc: 0.5936\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.68950\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 135s 2s/step - loss: 0.6897 - acc: 0.7478 - val_loss: 1.0764 - val_acc: 0.6473\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.68950\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6590 - acc: 0.7571 - val_loss: 0.8819 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.68950\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 143s 2s/step - loss: 0.6246 - acc: 0.7680 - val_loss: 1.0218 - val_acc: 0.6301\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.68950\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.7281 - acc: 0.7469 - val_loss: 0.9028 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.68950 to 0.70776, saving model to trained_model.h5\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6455 - acc: 0.7654 - val_loss: 1.1054 - val_acc: 0.6210\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.70776\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6456 - acc: 0.7782 - val_loss: 1.0940 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.70776\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.6413 - acc: 0.7672 - val_loss: 1.0817 - val_acc: 0.6347\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.70776\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6835 - acc: 0.7584 - val_loss: 1.0975 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.70776\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.6061 - acc: 0.7821 - val_loss: 1.0089 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.70776\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.6109 - acc: 0.7778 - val_loss: 1.1152 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.70776\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.6473 - acc: 0.7698 - val_loss: 1.0440 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.70776\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.6031 - acc: 0.7861 - val_loss: 1.0296 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.70776\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6166 - acc: 0.7799 - val_loss: 0.8428 - val_acc: 0.6804\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.70776\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.5750 - acc: 0.7896 - val_loss: 1.1075 - val_acc: 0.6804\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.70776\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.6168 - acc: 0.7751 - val_loss: 1.0525 - val_acc: 0.6575\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.70776\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.5790 - acc: 0.7825 - val_loss: 0.9952 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.70776\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 135s 2s/step - loss: 0.5669 - acc: 0.7979 - val_loss: 1.1520 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.70776\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.5580 - acc: 0.8041 - val_loss: 0.9623 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.70776\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.5481 - acc: 0.8024 - val_loss: 1.0109 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.70776\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.5287 - acc: 0.8081 - val_loss: 0.9401 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.70776 to 0.71233, saving model to trained_model.h5\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.5524 - acc: 0.8042 - val_loss: 0.8362 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.71233\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.5509 - acc: 0.8120 - val_loss: 0.8526 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.71233 to 0.73973, saving model to trained_model.h5\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 144s 2s/step - loss: 0.5579 - acc: 0.8016 - val_loss: 1.1456 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.73973\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 134s 2s/step - loss: 0.5550 - acc: 0.7901 - val_loss: 0.8327 - val_acc: 0.7443\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.73973 to 0.74429, saving model to trained_model.h5\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4998 - acc: 0.8182 - val_loss: 0.9204 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.74429\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.5012 - acc: 0.8248 - val_loss: 0.9192 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.74429\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4560 - acc: 0.8450 - val_loss: 0.9286 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.74429\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.5011 - acc: 0.8310 - val_loss: 1.2395 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.74429\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.5463 - acc: 0.8055 - val_loss: 0.8345 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.74429\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.4833 - acc: 0.8345 - val_loss: 0.8919 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.74429\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4739 - acc: 0.8253 - val_loss: 1.1293 - val_acc: 0.6712\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.74429\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 135s 2s/step - loss: 0.4646 - acc: 0.8398 - val_loss: 1.0976 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.74429\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 134s 2s/step - loss: 0.4179 - acc: 0.8578 - val_loss: 0.9856 - val_acc: 0.6518\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.74429\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.4642 - acc: 0.8323 - val_loss: 1.0603 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.74429\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.4178 - acc: 0.8552 - val_loss: 1.0598 - val_acc: 0.6758\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.74429\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4832 - acc: 0.8284 - val_loss: 0.9434 - val_acc: 0.7534\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.74429 to 0.75342, saving model to trained_model.h5\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4585 - acc: 0.8341 - val_loss: 1.1058 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.75342\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.4699 - acc: 0.8244 - val_loss: 0.9872 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.75342\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 134s 2s/step - loss: 0.4269 - acc: 0.8526 - val_loss: 1.1310 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.75342\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4534 - acc: 0.8393 - val_loss: 1.1159 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.75342\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.4540 - acc: 0.8358 - val_loss: 0.9594 - val_acc: 0.7545\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.75342 to 0.75446, saving model to trained_model.h5\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.4712 - acc: 0.8349 - val_loss: 0.8672 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.75446\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 136s 2s/step - loss: 0.4191 - acc: 0.8516 - val_loss: 0.9289 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.75446\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.4681 - acc: 0.8394 - val_loss: 1.0384 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.75446\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4043 - acc: 0.8574 - val_loss: 1.0790 - val_acc: 0.6804\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.75446\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.3863 - acc: 0.8644 - val_loss: 0.8780 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.75446\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.4299 - acc: 0.8442 - val_loss: 1.1360 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.75446\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.4658 - acc: 0.8393 - val_loss: 1.0627 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.75446\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.3984 - acc: 0.8565 - val_loss: 0.9949 - val_acc: 0.7277\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.75446\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.3808 - acc: 0.8618 - val_loss: 1.0768 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.75446\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4257 - acc: 0.8503 - val_loss: 1.6123 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.75446\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.3806 - acc: 0.8697 - val_loss: 1.1438 - val_acc: 0.7169\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.75446\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 141s 2s/step - loss: 0.4443 - acc: 0.8428 - val_loss: 0.7807 - val_acc: 0.7169\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.75446\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.3835 - acc: 0.8578 - val_loss: 1.1354 - val_acc: 0.6758\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.75446\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.3618 - acc: 0.8684 - val_loss: 1.0487 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.75446\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 172s 2s/step - loss: 0.4078 - acc: 0.8565 - val_loss: 1.0101 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.75446\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.4640 - acc: 0.8482 - val_loss: 1.0712 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.75446\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.3481 - acc: 0.8745 - val_loss: 0.9548 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.75446\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.3661 - acc: 0.8785 - val_loss: 1.0862 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.75446\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.3549 - acc: 0.8719 - val_loss: 1.1510 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.75446\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4242 - acc: 0.8447 - val_loss: 0.8036 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.75446 to 0.78995, saving model to trained_model.h5\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 137s 2s/step - loss: 0.3288 - acc: 0.8895 - val_loss: 1.2829 - val_acc: 0.7169\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.78995\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4023 - acc: 0.8658 - val_loss: 1.0854 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.78995\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 140s 2s/step - loss: 0.4213 - acc: 0.8460 - val_loss: 1.0612 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.78995\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4142 - acc: 0.8566 - val_loss: 1.2175 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.78995\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 138s 2s/step - loss: 0.3989 - acc: 0.8631 - val_loss: 1.3320 - val_acc: 0.6575\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.78995\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.4199 - acc: 0.8451 - val_loss: 0.8897 - val_acc: 0.7534\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.78995\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 139s 2s/step - loss: 0.3735 - acc: 0.8754 - val_loss: 1.1440 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.78995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x273ff688d68>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=100, steps_per_epoch=2276//32,validation_data=test_generator,\n",
    "                    validation_steps=251//32,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('garbage.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"garbage.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['cardboard','glass','metal','paper','plastic','trash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "predict_datagen = ImageDataGenerator(validation_split=0.1,rescale=1./255)\n",
    "\n",
    "img1 = cv2.imread('plas.jfif')\n",
    "img1 = cv2.resize(img1, (300, 300))\n",
    "img1 = img1.reshape(1, 300, 300, -1)\n",
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(img1)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
